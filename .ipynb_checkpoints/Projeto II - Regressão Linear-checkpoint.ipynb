{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>__MÉTODOS NUMÉRICOS__</center>\n",
    "## <center>__PROJETO DA UNIDADE 2__</center>\n",
    "\n",
    "#### <center>__ALUNO:__ Alfredo Rodrigo Sousa da Silva (201611250004)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "1. INTRODUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ___Machine Learning___, também conhecido em português como __aprendizado de máquina__, é o processo que possibilita que um computador, através de seus algoritmos, seja capaz de tomar decisões de acordo com aquilo que lhe é inserido. O aprendizado de máquina se baseia no treinamento dos algoritmos, fazendo com que estes aprendam a executar as tarefas, e não somente executem instruções pré-definidas. Desta forma, as máquinas conseguem procurar e encontrar, dentre uma grande quantidade de dados, informações importantes, sem exatamente saber o que estão procurando. Nesse sentido, existem alguns modelos de aprendizagem de máquina, que se baseiam em diferentes métodos para possibilitar esse aprendizado.\n",
    "\n",
    "O aprendizado de máquina vem para suprir diversas necessidades, e dentre elas, está a predição de valores. Quando queremos prever algo com base em alguns dados já existentes, nos utilizaremos de algum modelo de predição para isto. Dentre os diversos modelos de predição existentes, está o modelo de __regressão linear__.\n",
    "\n",
    "Ao longo deste documento, veremos exatamente a explicação da regressão linear, apresentando a sua motivação e observando o que esse tipo de regressão visa resolver; a implementação dos principais métodos aplicados à solução de regressão linear, utilizando a linguagem de programação Python e algumas de suas bibliotecas, além de métodos como o de solução ingênua, equações normais ou método de Cholesky e fatoração QR, entre outros; e alguns casos de uso, exemplificando e comparando o uso dos diversos métodos para a obtenção da regressão linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "2. DESCRIÇÃO DO PROBLEMA\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regressão linear é um método da álgebra linear que visa modelar uma relação entre uma variável dependente e uma ou mais variáveis independentes. Dependendo da quantidade de variáveis independentes que a função possui, a regressão linear pode ser do tipo simples, quando ela lida com somente uma variável independente, ou do tipo múltipla, também conhecido como multivariada, quando ela lida com duas ou mais variáveis independentes.\n",
    "\n",
    "Sobre esses dois tipos, de forma resumida, a regressão linear simples busca encontrar os coeficientes de uma função linear, a partir da relação entre a variável dependente $y$ e a variável independente $x$, enquanto que a regressão linear múltipla (multivariada) busca o mesmo fim, porém, ela relaciona uma variável dependente $y$ com duas ou mais variáveis independentes. Abaixo, somente para facilitar o entendimento do que foi dito, temos um exemplo de uma solução direta para a regressão linear a partir de um conjunto de dados 2D (BROWNLEE, 2018):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00233226]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeKklEQVR4nO3deXhV1bnH8e97I15Ra7GIWkAFRZGADBKw1rFOYK9X0NIrWqu9DtQBvTigoFZrHVDjrAwyOYAWlSEyBFNBEWSSQGSUYEQUiNYoRkQjJGHdP1aUBIM5wDlnn73P7/M8POacszn7vfsJv7537bXXMuccIiISfv8RdAEiIhIfCnQRkYhQoIuIRIQCXUQkIhToIiIRsUdQJz7ggANcs2bNgjq9iEgoLVy48AvnXKPaPgss0Js1a0Z+fn5QpxcRCSUz+3hHn2nIRUQkIhToIiIRoUAXEYkIBbqISEQo0EVEIkKBLiISETEFupl1NbNCMysys361fH6qmX1tZu9V/bkz/qWKiMjPqXMeupllAAOBM4F1wAIzm+icW7HdobOcc+ckoEYRkWgoL4dHHoHTT4dOneL+9bF06J2BIufcaufcFmAM0C3ulYiIRFlBARx3HPTvD+PGJeQUsQR6E2Bttdfrqt7b3vFmttjMpppZ69q+yMx6mVm+meWXlJTsQrkiIiHz/fdw++2+Iy8uhrFj4YEHEnKqWALdanlv+22OFgGHOefaAU8BObV9kXNuqHMuyzmX1ahRrUsRiIhEx+zZ0L493H8/XHIJU16ezgkf7E/zflM44YE3ySlYH9fTxRLo64BDqr1uChRXP8A5t9E5t6nq51ygnpkdELcqRUTC5Jtv4Lrr4KSTfIeel0fOdfdw87S1rC8twwHrS8voP35pXEM9lkBfABxpZs3NbE+gJzCx+gFmdrCZWdXPnau+98u4VSkiEhZ5edCmDQwc6EN92TI46yyy8wopK6+scWhZeSXZeYVxO3Wds1yccxVm1hvIAzKAkc655WZ2VdXnQ4AewNVmVgGUAT2ddp8WkXSyYQPceCM8/zwcfTTMmgUnnPDjx8WlZbX+tR29vytiWj63ahgld7v3hlT7+Wng6bhVJSISJuPGwbXXwhdf+Bugd9wBe+1V45DGDeqzvpbwbtygftzK0JOiIiK76tNP4Q9/gB49oEkTyM+He+/9SZgD9O3Skvr1Mmq8V79eBn27tIxbOYFtcCEiElrO+aGVG26AsjI/DfGmm2CPHUdq9w5+tnd2XiHFpWU0blCfvl1a/vh+PCjQRUR2xpo10KsXvPGGn8UyfDgcdVRMf7V7hyZxDfDtachFRCQWlZXw5JN+BsvcuX4Wy4wZMYd5MqhDFxGpy/vvwxVXwJw50LUrPPMMHHpo0FX9hDp0EZEdKS+H++7zT3uuXAkvvAC5uSkZ5qAOXUSkdosWwWWXweLF8D//44dbDjoo6Kp+ljp0EZHqysqgXz/o3Bk+/xwmTICXX075MAd16CIi28yc6cfKP/gALr8cHn4YGjQIuqqYqUMXEdm40T/pecopUFEB06b56YghCnNQoItIups61U9FHDwY+vSBpUv9jkIhpCEXEUlPX37pn/QcNQoyM/2UxN/8Juiqdos6dBFJL87BK69Aq1bwz3/CnXf6GS0hD3NQhy4i6aS4GK65Bl57DbKy/Fh527ZBVxU36tBFJPqcgxEj/NBKXh5kZ/vH9yMU5qAOXUSibvVquPJKePNNP4tl+HBo0SLoqhJCHbqIRFNlJTz+OBxzDCxYAEOG+FCPaJiDOnQRiaLly/2DQfPnw3/9lw/zpk2Drirh1KGLSHRs2QL33AMdOkBREbz4IkyalBZhDurQRSQqFizwXfnSpXDhhfDEE9CoUdBVJZU6dBEJt+++g759/TzyDRtg4kR46aW0C3NQhy4iYTZjhp/BUlTkt4V76CH45S+Driow6tBFJHy+/hquugp+9zs/x/zNN/0uQmkc5qBAF5GwmTIFWreGYcPgpptgyRIf7KJAF5GQKCmBP/0JzjkH9t/fP+n58MOw995BV5YyFOgiktqc84toZWbCq6/C3XfDwoV+RyGpQTdFRSR1rVsHV18Nkyf7AB8xwq9dLrVShy4iqWfrVhg61I+VT58Ojz7q1ytXmP8sdegiklqKivxUxBkz/M3OYcPgiCOCrioU1KGLSGqorIRHHvFL2i5a5IN8+nSF+U5Qhy4iwVu61D+2v2ABnHsuDBoETZoEXVXoqEMXkeBs3gx33QXHHgtr1sCYMZCTozDfRerQRSQY8+f7rnz5crj4YnjsMTjggKCrCjV16CKSXN9+CzfeCMcf7x/hnzwZRo1SmMdBTIFuZl3NrNDMisys388c18nMKs2sR/xKFJHIePNNf9Pzscf8WizLl/sNKCQu6gx0M8sABgJnA5nAhWaWuYPjHgTy4l2kiIRcaamfinj66ZCR4ackDhoE++0XdGWREkuH3hkocs6tds5tAcYA3Wo57jpgHPB5HOsTkbCbONE/IDRyJNxyCyxe7DdrlriLJdCbAGurvV5X9d6PzKwJcB4wJH6liUioff459OwJ3br58fH58+HBB6F+/aAri6xYAt1qec9t9/px4FbnXOXPfpFZLzPLN7P8kpKSGEsUkVBxDkaPhlatYMIEv8dnfj5kZQVdWeTFMm1xHXBItddNgeLtjskCxpgZwAHA782swjmXU/0g59xQYChAVlbW9v+jICJht3atv9mZm+u3hBsxwq+SKEkRS6AvAI40s+bAeqAncFH1A5xzzX/42cyeAyZvH+YiEmFbt/odg2691T/C/8QTcO21/gaoJE2dge6cqzCz3vjZKxnASOfccjO7qupzjZuLpLNVq/wMlpkz4Ywz/CqJzZvX/fck7mJ6UtQ5lwvkbvderUHunPvL7pclIimvosIva3vXXbDXXn4Wy1/+AlbbbTdJBj36LyI7b/FiuOwyvyrieefBwIHw61/H7etzCtaTnVdIcWkZjRvUp2+XlnTvoPVd6qJH/0Ukdps3w9/+5mesrFvnt4QbNy7uYd5//FLWl5bhgPWlZfQfv5ScgvVxO0dUKdBFJDZz50KHDnDvvXDRRbBiBfToEfchluy8QsrKa86ALiuvJDuvMK7niSIFuoj8vE2boE8fOOEEv7DW1Knw/PPQsGFCTldcWrZT78s2CnQR2bE33oBjjtk2DXHZMujaNaGnbNyg9idJd/S+bKNAF5Gf+uorf9PzrLPgP/8TZs2Cp56CX/wi4afu26Ul9evVnL9ev14Gfbu0TPi5w06zXESkpgkT4JproKQE+veHO+/00xKT5IfZLJrlsvMU6CLiffYZXHcdjB0L7dvDlCl+a7gAdO/QRAG+CzTkIpLunIMXXvBrrkyaBPffD+++G1iYy65Thy6Szj7+GP76V8jL87NYhg+Ho48OuirZRerQRdLR1q3w9NN+44l33vE3PGfOVJiHnDp0kXRTWAiXXw6zZ0OXLn6VxMMOC7oqiQN16CLporwcBgyAdu38U57PPecfElKYR4Y6dJEkCXTBqYIC35UXFPjH9Z96Cg4+ODnnlqRRhy6SBIEtOPX993DbbdCpE3z6qV9I69VXFeYRpUAXSYJAFpx65x0/n3zAALjkEj/Mcv75iTufBE6BLpIESV1w6ptvoHdvOOkkv9ztv/7lN5/Yf//4n0tSigJdJAmStuBUXh60aQODBsH118PSpXDmmfE9h6QsBbpIEiR8wakNG+DSS/1KiHvv7YdbnngC9t03Pt8voaBZLiJJkNAFp8aO9UvbbtgAd9wBt9+e1MW0JHUo0EWSJO4LTn36qQ/yCROgY0c/Vt6uXfy+X0JHQy4iYeMcPPusX0xr6lR48EGYN09hLurQRULlo4+gVy+YNs3PYhk+HI46KuiqJEWoQxcJg8pKePJJP4Nl3jw/i2XGDIW51KAOXSTVvf++f2x/7lw4+2wYMgQOPTToqiQFqUMXSVXl5XDfff5pz1WrYNQov4uQwlx2QB26SCpauNBv0rxkCVxwgR9uOfDAoKuSFKcOXSSVlJXBrbdC585+k+acHBgzRmEuMVGHLpIqZs6EK66ADz7w/83OhgYNgq5KQkQdukjQNm6Ea66BU06Bigo/JXHYMIW57DQFukiQcnP9VMRnnoEbb/SLaZ1+etBVSUhpyEUkCF98ATfcAKNH+yc+58yB444LuioJOXXoIsnkHLz8sg/xMWPgrrtg0SKFucSFOnSRZCku9mPlr70GWVkwfTocc0zQVUmEqEMXSTTn/JormZl+A4rsbP/Up8Jc4iymQDezrmZWaGZFZtavls+7mdkSM3vPzPLN7MT4lyoSQqtXwxlnwJVX+ic+ly6Fm2+GPfT/HEv81RnoZpYBDATOBjKBC80sc7vDpgPtnHPtgcuA4XGuUyRcKivhscf8DJb8fD+L5c03oUWLoCuTCIulTegMFDnnVgOY2RigG7DihwOcc5uqHb8P4OJZpEioLFvmHwyaPx/OOQcGD4amTYOuStJALEMuTYC11V6vq3qvBjM7z8xWAlPwXfpPmFmvqiGZ/JKSkl2pVyR1bdkCd98Nxx4LH34IL70EEycqzCVpYgl0q+W9n3TgzrkJzrmjge7APbV9kXNuqHMuyzmX1ahRo50qVCSlLVjgt4H7+9/hj3+EFSvgwgvBavvnI5IYsQT6OuCQaq+bAsU7Otg5NxM4wswO2M3aRFLfd9/5m5y/+Q189ZXvyF98EdSwSABiCfQFwJFm1tzM9gR6AhOrH2BmLcx8K2JmxwJ7Al/Gu1iRlDJjBrRtC4884mexLF8O//3fQVclaazOm6LOuQoz6w3kARnASOfccjO7qurzIcAfgEvMrBwoAy5wzunGqETT11/DLbfA0KFwxBHw1ltw6qlBVyWCBZW7WVlZLj8/P5Bzi+yySZPgqqvgs8/8Ylp33w177x10VZJGzGyhcy6rts/0pKhILEpK4KKL4NxzoWFDv1FzdrbCXFKKAl3k5zjnpx+2agVjx/qOPD8fOnUKujKRn9DzxyI7sm4dXH01TJ7sV0McMQJatw66KpEdUocusr2tW/2j+pmZfkXERx+F2bMV5pLy1KGLVFdU5KcgzpgBp53mt4I7/PCgqxKJiTp0EfB7eT78sF/StqDAL3c7bZrCXEJFHbrIkiVw+eX+Zme3bjBoEDRuHHRVIjtNHbqkr82b/RZwHTvCxx/7reEmTFCYS2ipQ5f0NG+e78pXrICLL4bHH/fzy0VCTB26pJdvv/VPeP72t7BxI0yZAqNGKcwlEtShS/qYPt3PYPnoI79Z84ABsN9+QVclEjfq0CX6Skv9DkJnnOH38nz7bRg4UGEukaNAl2h77TX/gNBzz8Gtt8LixXDyyUFXJZIQGnKRaPr3v+H66+GVV6BdO79KYseOQVclklDq0CVanIPRo31XnpMD9967bXs4kYhThy7R8cknfq3yqVPh+OP9YlqtWgVdlUjSqEOX8Nu61T/d2bq1v+H5xBMwa5bCXNKOOnQJt1Wr/AyWWbPgzDP9tnDNmgVdlUgg1KFLOFVUwIMP+k2aly6FZ5+FvDyFuaQ1degSPosXw2WXwaJFcN55fk75r38ddFUigVOHLuHx/fdwxx2QlQXr1/st4caPV5iLVFGHLuEwZ45fTGvlSrj0Ur+L0K9+FXRVIilFHbqktk2b/ANCJ54I330Hr7/un/pUmIv8hAJdUte//gVt2sDTT8O118KyZdClS9BViaQsBbqknq++gv/9Xx/ee+0FM2fCU0/BL34RdGUiKU2BLqll/Hj/2P6oUdC/P7z3nh9uEZE66aao/CinYD3ZeYUUl5bRuEF9+nZpSfcOTZJz8s8+g969Ydw4aN8ecnOhQ4fknFskItShC+DDvP/4pawvLcMB60vL6D9+KTkF6xN7Yuf8Tc7MTJg8Ge6/H959V2EusgsU6AJAdl4hZeWVNd4rK68kO68wcSddswa6dvXj5ZmZfnilf3+oVy9x5xSJMAW6AFBcWrZT7++WrVv9Tc42bfz88qef9jc+jz46/ucSSSMKdAGgcYP6O/X+Llu50u8Y9MPc8mXL/JTE/9Cvosju0r8iAaBvl5bUr5dR47369TLo26VlfE5QXu7Hx9u1gxUr4Pnn/brlhx0Wn+8XEc1yEe+H2SwJmeWyaJF/bP+996BHDz/EctBBu/+9IlKDAl1+1L1Dk/hOUywrg3/8A7KzoVEjPyXx/PPj9/0iUoMCXRLjnXd8V75qlV/q9uGHYf/9g65KJNJiGkM3s65mVmhmRWbWr5bP/2RmS6r+zDGzdvEvVULhm2/8A0InnQRbtsAbb/i9PRXmIglXZ6CbWQYwEDgbyAQuNLPM7Q77CDjFOdcWuAcYGu9CJQRef91PRRw0CP7v//xOQmecEXRVImkjlg69M1DknFvtnNsCjAG6VT/AOTfHOfdV1ct5QNP4likp7csv/RrlZ58N++wDs2fD44/DvvsGXZlIWokl0JsAa6u9Xlf13o5cDkyt7QMz62Vm+WaWX1JSEnuVkpqcg1df9U95vvSS302ooACOPz7oykTSUiw3Ra2W91ytB5r9Dh/otS6P55wbStVwTFZWVq3fISHx6adwzTWQkwMdO/q1y9vp1olIkGLp0NcBh1R73RQo3v4gM2sLDAe6Oee+jE95knKcg5EjoVUrP2b+0EMwb57CXCQFxBLoC4Ajzay5me0J9AQmVj/AzA4FxgN/ds6tin+ZkhI++gjOOstPR2zXDhYvhr59YQ/NfhVJBXX+S3TOVZhZbyAPyABGOueWm9lVVZ8PAe4EGgKDzAygwjmXlbiyJakqK/3TnbfdBhkZMHgw9Oql9VdEUow5F8xQdlZWlsvPzw/k3LITVqzwHfm8eX4WyzPPwCGH1P33RCQhzGzhjhpmtVhSuy1b4J57/EYTH3wAo0fDlCkKc5EUpsFP+an8fN+VL1kCF1wATz4JBx4YdFUiUgd16LJNWRnccgscdxx88YWfkjhmjMJcJCTUoYv39ttwxRVQVOT/m50NDRoEXZWI7AR16Olu40a4+mo49VS/Ndz06TBsmMJcJIQU6OlsyhRo3RqGDoUbb/Rj5qedFnRVIrKLFOjp6Isv4OKL4ZxzYL/9/EbNjzziF9YSkdBSoKcT5/xNzlat4OWX4a67/PZwxx0XdGUiEge6KZou1q/3i2lNnAidOvlNJ445JuiqRCSO1KFHnXP+Jmdmpt896OGHYe5chblIBKlDj7IPP4Qrr4S33vKzWIYNgxYtgq5KRBJEHXoUVVbCo4/6LnzhQr/+yvTpCnORiFOHHjXLlvnH9t99189iGTwYmmpHQJF0oA49KrZsgbvvhmOPhdWr/ZZwEycqzEXSiDr0KHj3Xd+VL1sGF13kN2hu1CjoqkQkydShh9l338FNN/lNmb/6CiZNghdfVJiLpCl16GH11lt+Ea3Vq+Gvf4UHH4Rf/jLoqkQkQOrQw+brr/32b6edBmY+2IcMUZiLiAI9VCZN8g8IjRgBN9/sF9M69dSgqxKRFKFAD4OSErjwQjj3XGjY0O/vmZ0Ne+8ddGUikkIU6KnMOX+Ts1UrGDcO/vEPvz1cp05BVyYiKUg3RVPV2rV+44kpU/xqiCNG+LXLRUR2QB16qtm61d/kbN3a3/B87DGYPVthLiJ1UoeeSj74wC+m9fbbcPrpfiehww8PuioRCQl16KmgosLf5GzbFt57D4YP90vdKsxFZCeoQw/akiX+sf38fOjWDQYNgsaNg65KREIoVIGeU7Ce7LxCikvLaNygPn27tKR7hyZBl7VrNm+G++6DAQPgV7+CV16BHj38w0IiIrsgNIGeU7Ce/uOXUlZeCcD60jL6j18KEL5QnzvXd+Xvvw9//rO/8dmwYdBViUjIhWYMPTuv8Mcw/0FZeSXZeYUBVbQLvv0W+vSBE06ATZsgNxdeeEFhLiJxEZoOvbi0bKfeTznTpvkZLGvW+M2aBwyA/fYLuioRiZDQdOiNG9TfqfdTRmmpH14580yoV89PSRw4UGEuInEXmkDv26Ul9etl1Hivfr0M+nZpGVBFMcjJ8YtpPf889OsHixfDyScHXZWIRFRohlx+uPEZilku//43XHcdvPoqtGvnV0ns2DHoqkQk4kIT6OBDPSUD/AfOwahR/sbnt9/6aYl9+/qhFhGRBAtVoKe0Tz7xOwe9/rrfEm7ECL9KoohIksQ0hm5mXc2s0MyKzKxfLZ8fbWZzzWyzmd0c/zJT2Nat/iZn69YwaxY8+aT/r8JcRJKszg7dzDKAgcCZwDpggZlNdM6tqHbYBuB6oHsiikxZhYV+X8933vGzWIYOhWbNgq5KRNJULB16Z6DIObfaObcFGAN0q36Ac+5z59wCoDwBNaae8nJ44AF/w3PZMnj2WcjLU5iLSKBiGUNvAqyt9nodcNyunMzMegG9AA499NBd+YrgFRT4eeUFBXD++X645eCDg65KRCSmDr221aLcrpzMOTfUOZflnMtq1KjRrnxFcL7/Hm6/3W//VlwMY8f6beEU5iKSImLp0NcBh1R73RQoTkw5KWr2bN+VFxbCpZfCo4/6FRJFRFJILB36AuBIM2tuZnsCPYGJiS0rRWzaBNdfDyed5Dv011+H555TmItISqqzQ3fOVZhZbyAPyABGOueWm9lVVZ8PMbODgXxgP2CrmfUBMp1zGxNXeoLl5fl55Z98Ar17w/33w777Bl2ViMgOxfRgkXMuF8jd7r0h1X7+DD8UE34bNsCNN/r1V1q29HPKTzgh6KpEROoUmsW5kmLcOL+Y1ujRcNttfn9PhbmIhIQe/Qf49FM/rDJ+PHTo4MfK27cPuioRkZ2S3h26c/4mZ2YmTJniN52YP19hLiKhlL4d+po10KsXvPEGnHgiDB/ux8xFREIq/Tr0ykp46ilo08Zv1jxwoN9FSGEuIiGXXh36++/7xbTmzIGuXWHIEDjssKCrEhGJi/To0MvL/WYT7dvDypXwwguQm6swF5FIiX6HvmgRXHaZ38/zj3/0wy0HHRR0VSIicRfdDr2szG/M3Lmz3+Nz/Hh45RWFuYhEVjQ79Fmz/Fj5qlV+Ua3sbNh//6CrEhFJqGh16Bs3wrXXwsknw5Ytfkri8OEKcxFJC9EJ9KlT/VTEwYOhTx+/k9AZZwRdlYhI0oQ/0L/8Ei65BH7/e78a4uzZ8NhjsM8+QVcmIpJU4Q105/xNzlat4J//hL/9zW8Ld/zxQVcmIhKIcN4ULS72Y+U5OdCxI0ybBm3bBl2ViEigwhfoublw0UWweTM89BDccAPsEb7/M0RE4i18SXjUUX5Y5ckn4cgjg65GRCRlhC/QW7TwM1pERKSG8N4UFRGRGhToIiIRoUAXEYkIBbqISEQo0EVEIkKBLiISEQp0EZGIUKCLiESEOeeCObFZCfBxICePnwOAL4IuIoXoetSk67GNrkVNu3M9DnPONartg8ACPQrMLN85lxV0HalC16MmXY9tdC1qStT10JCLiEhEKNBFRCJCgb57hgZdQIrR9ahJ12MbXYuaEnI9NIYuIhIR6tBFRCJCgS4iEhEK9BiYWVczKzSzIjPrV8vnR5vZXDPbbGY3B1FjssRwLf5kZkuq/swxs3ZB1JksMVyPblXX4j0zyzezE4OoM1nquh7VjutkZpVm1iOZ9SVTDL8bp5rZ11W/G++Z2Z27fVLnnP78zB8gA/gQOBzYE1gMZG53zIFAJ+A+4Oagaw74WvwW2L/q57OB+UHXHfD12Jdt96raAiuDrjvI61HtuDeBXKBH0HUH+LtxKjA5nudVh163zkCRc261c24LMAboVv0A59znzrkFQHkQBSZRLNdijnPuq6qX84CmSa4xmWK5Hptc1b9eYB8gyrMQ6rweVa4DxgGfJ7O4JIv1WsSVAr1uTYC11V6vq3ovHe3stbgciPIGsDFdDzM7z8xWAlOAy5JUWxDqvB5m1gQ4DxiSxLqCEOu/lePNbLGZTTWz1rt7UgV63ayW96LcZf2cmK+Fmf0OH+i3JrSiYMV0PZxzE5xzRwPdgXsSXVSAYrkejwO3OucqE19OoGK5Fovw67K0A54Ccnb3pAr0uq0DDqn2uilQHFAtQYvpWphZW2A40M0592WSagvCTv1uOOdmAkeY2QGJLiwgsVyPLGCMma0BegCDzKx7UqpLrjqvhXNuo3NuU9XPuUC93f3dUKDXbQFwpJk1N7M9gZ7AxIBrCkqd18LMDgXGA392zq0KoMZkiuV6tDAzq/r5WPwNsqj+j1yd18M519w518w51wwYC1zjnMtJeqWJF8vvxsHVfjc64/N4t3439tidv5wOnHMVZtYbyMPfuR7pnFtuZldVfT7EzA4G8oH9gK1m1gd/R3tjUHUnQizXArgTaIjvvAAqXERX2YvxevwBuMTMyoEy4IJqN0kjJcbrkRZivBY9gKvNrAL/u9Fzd3839Oi/iEhEaMhFRCQiFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnQRkYj4f+geSHs6JpEjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# solve directly\n",
    "from numpy import array\n",
    "from numpy.linalg import inv\n",
    "from matplotlib import pyplot\n",
    "\n",
    "data = array([\n",
    "    [0.05, 0.12],\n",
    "    [0.18, 0.22],\n",
    "    [0.31, 0.35],\n",
    "    [0.42, 0.38],\n",
    "    [0.5, 0.49],\n",
    "    ])\n",
    "\n",
    "X, y = data[:,0], data[:,1]\n",
    "X = X.reshape((len(X), 1))\n",
    "\n",
    "# linear least squares\n",
    "b = inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "print(b)\n",
    "\n",
    "# predict using coefficients\n",
    "yhat = X.dot(b)\n",
    "\n",
    "# plot data and predictions\n",
    "pyplot.scatter(X, y)\n",
    "pyplot.plot(X, yhat, color='red')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Gráfico de dispersão da solução direta para o problema de regressão linear)\n",
    "\n",
    "A regressão linear resulta em uma função linear do tipo $y = ax + b$, onde esta função descreve uma tendência entre as variáveis do conjunto de dados aplicado, evidenciando a relação entre elas. No gráfico acima, essa função está sendo representada pela reta vermelha, onde podemos observar que ela tende em se ajustar entre os valores do conjunto de dados.\n",
    "\n",
    "A regressão linear torna possível a predição de valores com base em um conjunto de dados pré-existente. Ela pode ser utilizada, por exemplo, para determinar o valor de um imóvel de acordo com sua localização ou ano de construção, ou para prever se haverá um terremoto em algum determinado dia, a partir de dados sismológicos anteriores, ou até mesmo para estimar a progressão de uma doença ao longo do tempo. Esta última aplicabilidade será melhor descrita neste documento, na Seção 5. CASOS DE USO, por meio de um exemplo.\n",
    "\n",
    "<blockquote>\n",
    "<b>Observação:</b>\n",
    "    \n",
    "É importante notar que, apesar de o resultado da regressão linear ser uma predição, não significa exatamente que o previsto irá acontecer. Neste caso, quando for necessário prever algo, é interessante que se use também, além da regressão linear, outras ferramentas de predição, observando o contexto e a necessidade de cada problema.\n",
    "</blockquote>\n",
    "\n",
    "A regressão linear pode ser implementada utilizando diferentes métodos, que por sua vez possuem diferentes medidas de desempenho, e devem ser utilizados de acordo com a necessidade, já que o método que resolve um problema pode não resolver outro com a mesma eficiência. Na próxima Seção (3. MÉTODOS APLICADOS À SOLUÇÃO), veremos a descrição dos métodos numéricos que são utilizados para implementar a regressão linear, a saber: solução ingênua, Cholesky, fatoração QR e SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "3. MÉTODOS APLICADOS À SOLUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solucionar os problemas de refressão linear, podemos utilizar vários algoritmos. Abaixo, está descrita a solução ingênua para a regressão linear, que se utiliza de equações normais, além dos métodos de Cholesky, fatoração QR e SVD.\n",
    "\n",
    "Antes de explicar cada método, se faz necessário o entendimento sobre mínimos quadrados e equações normais, assuntos esses que estão explicados a seguir.\n",
    "\n",
    "<div class=\"alert\">\n",
    "3.1. MÍNIMOS QUADRADOS E EQUAÇÕES NORMAIS\n",
    "</div>\n",
    "\n",
    "A regressão linear torna possível a predição de valores a partir da modelagem de uma relação entre uma variável dependente e uma ou mais variáveis independentes. Com ela, podemos estimar valores utilizando um conjunto de dados pré-existente. Para isso, a regressão linear se utiliza do __método dos mínimos quadrados__ para encontrar um melhor ajuste para um conjunto de dados, minimizando a soma dos quadrados das diferenças entre o valor previsto e o valor real:\n",
    "\n",
    "$$||Ax-b||_2$$\n",
    "\n",
    "Para que essa minimização seja feita, podemos pensar que \"estamos interessados em onde o vetor $b$ está mais próximo do subespaço estentido por $A$ (chamado de intervalo de $A$)\". (THOMAS, 2017). Pensando dessa forma, esse espaço é exatamente a projeção do vetor $b$ em $A$. Então, como $b-Ax$ é ortogonal, ou seja, é perpendicular a todas as colunas de $A$ (GRAÇA, 2016), então:\n",
    "\n",
    "$$A^T(b-Ax) = 0$$\n",
    "\n",
    "Abaixo, temos uma figura que demonstra a projeção de $b$ em $A$, e a perpendicularidade de $b - Ax$ em relação a $A$:\n",
    "\n",
    "<center><br><b>Figura 1</b> - Perpendicular</center>\n",
    "<img src=\"https://raw.githubusercontent.com/AlfredoRodrigo/regressao_linear_-_metodos_numericos/main/imagens/Perpendicular.png?token=AFNDACB63IJDC6ZT2JPTOTLAS7NVY\">\n",
    "<center>Fonte: GRAÇA, 2016.</center>\n",
    "\n",
    "Assim, como $A^T(b-Ax) = 0$, então, reescrevendo essa fórmula, temos as __equações normais__ como sendo:\n",
    "\n",
    "$$A^TAx = A^Tb$$\n",
    "\n",
    "Essas equações também podem ser escritas da forma:\n",
    "\n",
    "$$x = (A^TA)^{-1}A^Tb$$\n",
    "\n",
    "<div class=\"alert\">\n",
    "3.2. SOLUÇÃO INGÊNUA\n",
    "</div>\n",
    "\n",
    "A solução ingênua (também chamada de solução direta) recebe esse nome por ser o método mais simples de resolução da regressão linear, mas que ao mesmo tempo não resolve todos os casos de maneira eficiente. Ela implementa exatamente a forma mais simples das equações normais, ou seja, $x = (A^TA)^{-1}A^Tb$, onde $x$ é o vetor resultado da regressão linear.\n",
    "\n",
    "<div class=\"alert\">\n",
    "3.3. CHOLESKY\n",
    "</div>\n",
    "\n",
    "O método de Cholesky para regressão linear utiliza o mesmo princípio de funcionamento do método da decomposição LU.\n",
    "<blockquote>\n",
    "<b>Para relembrar:</b>\n",
    "    \n",
    "A decomposição LU é um método que decompõe a matriz $A$ em um produto $A = LU$, onde as matrizes $L$ e $U$ são triangulares inferiores e superiores, respectivamente.\n",
    "</blockquote>\n",
    "\n",
    "<div class=\"alert\">\n",
    "3.4. FATORAÇÃO QR\n",
    "</div>\n",
    "\n",
    "A fatoração QR de uma matriz, também conhecida como decomposição QR, é um método que decompõe uma matriz $A$ em um produto $A = QR$ de uma matriz ortogonal $Q$ e uma matriz triangular superior $R$. A fatoração QR é frequentemente usada para resolver o problema de mínimos quadrados linear e é a base para um determinado algoritmo de autovalores, o algoritmo QR.\n",
    "\n",
    "Cholesky, semelhantemente, fatora a matriz $A$ em outras duas matrizes, sendo uma triangular inferior e outra triangular superior. Porém, esta segunda é exatamente a matriz transversa da primeira, ou seja:\n",
    "\n",
    "$$A = LL^T$$\n",
    "\n",
    "<div class=\"alert\">\n",
    "3.5. SVD\n",
    "</div>\n",
    "\n",
    "A sigla SVD vem do inglês _singular value decomposition_, que em tradução no português, significa __decomposição em valores singulares__. Esse método de regressão linear consiste em"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "4. IMPLEMENTAÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui você irá  mostrar sua implementação para o problema considerado, explicando o que foi feito em cada passo e cada saída de cada trecho de código, sempre relacionando com a descrição do método mostrada acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "5. CASOS DE USO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa seção, você aplicará sua implementação em pelo menos dois casos: um é o caso descrito nas referências, e outro, um caso similar que você encontrará e testará sua implementação. __Cuidado para evitar casos iguais aos demais colegas!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  0.  0.  0.]\n",
      " [-1.  3.  0.  0.]\n",
      " [ 2.  1.  1.  0.]\n",
      " [ 5.  1.  2.  1.]]\n",
      "-------------------------\n",
      "[[ 2. -1.  2.  5.]\n",
      " [ 0.  3.  1.  1.]\n",
      " [ 0.  0.  1.  2.]\n",
      " [ 0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "import numpy as np\n",
    "\n",
    "B = np.array([[4, -2, 4, 10],\n",
    "              [-2, 10, 1, -2],\n",
    "              [4 ,1 ,6 ,13],\n",
    "              [10, -2, 13, 31]])\n",
    "\n",
    "L = scipy.linalg.cholesky(B, lower=True) #retorna L\n",
    "Lt = scipy.linalg.cholesky(B) #retorna L^T\n",
    "\n",
    "print(L)\n",
    "print(\"-------------------------\")\n",
    "print(Lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -25.713473, -224.323015,  496.729726,  341.281487, -898.85267 ,\n",
       "        569.962979,  182.734949,  163.778935,  852.143775,   75.318523,\n",
       "        151.323305])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import math, scipy, numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "np.set_printoptions(precision=6)\n",
    "\n",
    "data = datasets.load_diabetes()\n",
    "\n",
    "#print(data.data.shape)\n",
    "\n",
    "#print(data.target.shape)\n",
    "\n",
    "feature_names=['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
    "\n",
    "trn,test,y_trn,y_test = train_test_split(data.data, data.target, test_size=0.2)\n",
    "\n",
    "trn_int = np.c_[trn, np.ones(trn.shape[0])]\n",
    "\n",
    "#def ls_chol(A, b):\n",
    "#    R = scipy.linalg.cholesky(A.T @ A)\n",
    "#    w = scipy.linalg.solve_triangular(R, A.T @ b, trans='T')\n",
    "#    return scipy.linalg.solve_triangular(R, w)\n",
    "\n",
    "def ls_chol(A, b):\n",
    "    R = scipy.linalg.cholesky(A.T @ A)\n",
    "    w = scipy.linalg.solve_triangular(R, A.T @ b, trans='T')\n",
    "    return scipy.linalg.solve_triangular(R, w)\n",
    "\n",
    "coeffs_chol = ls_chol(trn_int, y_trn)\n",
    "\n",
    "coeffs_chol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Ax = b$$\n",
    "\n",
    "Seja sempre $Q$ uma matriz ortogonal. Se $A = QR$, então\n",
    "\n",
    "$$QRx = b$$\n",
    "\n",
    "Multiplicando ambos os lados por $Q^T$, temos:\n",
    "\n",
    "$$Q^TQRx = Q^Tb$$\n",
    "\n",
    "Tem uma propriedade que diz que $Q^T$ = $Q^{-1}$. Desta forma, modificando a fórmula acima, temos:\n",
    "\n",
    "$$Q^{-1}QRx = Q^{-1}b$$\n",
    "\n",
    "Tem outra propriedade que diz que, dada uma matriz $M$ quadrada invertível, então:\n",
    "\n",
    "$$MM^{-1} = M^{-1}M = I (identidade)$$\n",
    "\n",
    "Já que toda matriz ortogonal é invertível, e como a matriz tratata é quadrada, então:\n",
    "\n",
    "$$QQ^{-1} = Q^{-1}Q = I (identidade)$$\n",
    "\n",
    "Logo,\n",
    "\n",
    "$$Q^{-1}QRx = Q^{-1}b$$\n",
    "$$IRx = Q^{-1}b$$\n",
    "\n",
    "Pelas propriedades de identidade, qualquer matriz $A$ multiplicada pela sua identidade $I$ é igual a própria matriz $A$. Desta forma, se $AI = IA = A$, então:\n",
    "\n",
    "$$IR = RI = R$$\n",
    "\n",
    "Logo,\n",
    "\n",
    "$$IRx = Q^{-1}b$$\n",
    "$$Rx = Q^{-1}b$$\n",
    "\n",
    "Como $Q$ é ortogonal, e sabendo que $Q^{-1}$ = $Q^T$, então:\n",
    "\n",
    "$$Rx = Q^Tb$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
