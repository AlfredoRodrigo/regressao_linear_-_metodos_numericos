{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>__MÉTODOS NUMÉRICOS__</center>\n",
    "## <center>__PROJETO DA UNIDADE 2__</center>\n",
    "\n",
    "#### <center>__ALUNO:__ Alfredo Rodrigo Sousa da Silva (201611250004)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "1. INTRODUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ___Machine Learning___, também conhecido em português como __aprendizado de máquina__, é o processo que possibilita que um computador, através de seus algoritmos, seja capaz de tomar decisões de acordo com aquilo que lhe é inserido. O aprendizado de máquina se baseia no treinamento dos algoritmos, fazendo com que estes aprendam a executar as tarefas, e não somente executem instruções pré-definidas. Desta forma, as máquinas conseguem procurar e encontrar, dentre uma grande quantidade de dados, informações importantes, sem exatamente saber o que estão procurando. Nesse sentido, existem alguns modelos de aprendizagem de máquina, que se baseiam em diferentes métodos para possibilitar esse aprendizado.\n",
    "\n",
    "O aprendizado de máquina vem para suprir diversas necessidades, e dentre elas, está a predição de valores. Quando queremos prever algo com base em alguns dados já existentes, nos utilizaremos de algum modelo de predição para isto. Dentre os diversos modelos de predição existentes, está o modelo de __regressão linear__.\n",
    "\n",
    "Ao longo deste documento, veremos exatamente a explicação da regressão linear, apresentando a sua motivação e observando o que esse tipo de regressão visa resolver; a implementação dos principais métodos aplicados à solução de regressão linear, utilizando a linguagem de programação Python e algumas de suas bibliotecas, além de métodos como o de solução ingênua, equações normais ou método de Cholesky e fatoração QR, entre outros; e alguns casos de uso, exemplificando e comparando o uso dos diversos métodos para a obtenção da regressão linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "2. DESCRIÇÃO DO PROBLEMA\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regressão linear é um método da álgebra linear que visa modelar uma relação entre uma variável dependente e uma ou mais variáveis independentes. Dependendo da quantidade de variáveis independentes que a função possui, a regressão linear pode ser do tipo simples, quando ela lida com somente uma variável independente, ou do tipo múltipla, também conhecido como multivariada, quando ela lida com duas ou mais variáveis independentes.\n",
    "\n",
    "Sobre esses dois tipos, de forma resumida, a regressão linear simples busca encontrar os coeficientes de uma função linear, a partir da relação entre a variável dependente $y$ e a variável independente $x$, enquanto que a regressão linear múltipla (multivariada) busca o mesmo fim, porém, ela relaciona uma variável dependente $y$ com duas ou mais variáveis independentes. Abaixo, somente para facilitar o entendimento do que foi dito, temos um exemplo de uma solução direta para a regressão linear a partir de um conjunto de dados 2D (BROWNLEE, 2018):\n",
    "\n",
    "<center><br><b>Figura 1</b> - Gráfico de dispersão da solução direta para o problema de regressão linear do exemplo citado</center>\n",
    "<img src=\"https://raw.githubusercontent.com/AlfredoRodrigo/regressao_linear_-_metodos_numericos/main/imagens/Gr%C3%A1fico%20de%20dispers%C3%A3o%20da%20solu%C3%A7%C3%A3o%20direta%20para%20o%20problema%20de%20regress%C3%A3o%20linear%20do%20exemplo%20do%20Brownlee%20(2018).png\">\n",
    "<center>Fonte: BROWNLEE, 2018.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regressão linear resulta em uma função linear do tipo $y = ax + b$, onde esta função descreve uma tendência entre as variáveis do conjunto de dados aplicado, evidenciando a relação entre elas. No gráfico acima, essa função está sendo representada pela reta vermelha, onde podemos observar que ela tende em se ajustar entre os valores do conjunto de dados.\n",
    "\n",
    "A regressão linear torna possível a predição de valores com base em um conjunto de dados pré-existente. Ela pode ser utilizada, por exemplo, para determinar o valor de um imóvel de acordo com sua localização ou ano de construção, ou para prever se haverá um terremoto em algum determinado dia, a partir de dados sismológicos anteriores, ou até mesmo para estimar a progressão de uma doença ao longo do tempo. Esta última aplicabilidade será melhor descrita neste documento, na Seção 5. CASOS DE USO, por meio de um exemplo.\n",
    "\n",
    "<blockquote>\n",
    "<b>Observação:</b>\n",
    "    \n",
    "É importante notar que, apesar de o resultado da regressão linear ser uma predição, não significa exatamente que o previsto irá acontecer. Neste caso, quando for necessário prever algo, é interessante que se use também, além da regressão linear, outras ferramentas de predição, observando o contexto e a necessidade de cada problema.\n",
    "</blockquote>\n",
    "\n",
    "A regressão linear pode ser implementada utilizando diferentes métodos, que por sua vez possuem diferentes medidas de desempenho, e devem ser utilizados de acordo com a necessidade, já que o método que resolve um problema pode não resolver outro com a mesma eficiência. Na próxima Seção (3. MÉTODOS APLICADOS À SOLUÇÃO), veremos a descrição dos métodos numéricos que são utilizados para implementar a regressão linear, a saber: solução ingênua, Cholesky, fatoração QR e SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "3. MÉTODOS APLICADOS À SOLUÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solucionar os problemas de regressão linear, podemos utilizar vários algoritmos. Abaixo, está descrita a solução ingênua para a regressão linear, que se utiliza de equações normais, além dos métodos de Cholesky, fatoração QR e SVD.\n",
    "\n",
    "Antes de explicar cada método, se faz necessário o entendimento sobre mínimos quadrados e equações normais, assuntos esses que estão explicados a seguir.\n",
    "\n",
    "<div class=\"alert\">\n",
    "3.1. MÍNIMOS QUADRADOS E EQUAÇÕES NORMAIS\n",
    "</div>\n",
    "\n",
    "A regressão linear torna possível a predição de valores a partir da modelagem de uma relação entre uma variável dependente e uma ou mais variáveis independentes. Com ela, podemos estimar valores utilizando um conjunto de dados pré-existente. Para isso, a regressão linear se utiliza do __método dos mínimos quadrados__ para encontrar um melhor ajuste para um conjunto de dados, minimizando a soma dos quadrados das diferenças entre o valor previsto e o valor real:\n",
    "\n",
    "$$||Ax-b||_2$$\n",
    "\n",
    "Para que essa minimização seja feita, podemos pensar que \"estamos interessados em onde o vetor $b$ está mais próximo do subespaço estentido por $A$ (chamado de intervalo de $A$)\". (THOMAS, 2017). Pensando dessa forma, esse espaço é exatamente a projeção do vetor $b$ em $A$. Então, como $b-Ax$ é ortogonal, ou seja, é perpendicular a todas as colunas de $A$ (GRAÇA, 2016), então:\n",
    "\n",
    "$$A^T(b-Ax) = 0$$\n",
    "\n",
    "Abaixo, temos uma figura que demonstra a projeção de $b$ em $A$, e a perpendicularidade de $b - Ax$ em relação a $A$:\n",
    "\n",
    "<center><br><b>Figura 2</b> - Perpendicular</center>\n",
    "<img src=\"https://raw.githubusercontent.com/AlfredoRodrigo/regressao_linear_-_metodos_numericos/main/imagens/Perpendicular%20(GRA%C3%87A%2C%202016).png\">\n",
    "<center>Fonte: GRAÇA, 2016.</center>\n",
    "\n",
    "Assim, como $A^T(b-Ax) = 0$, então, reescrevendo essa fórmula, temos as __equações normais__ como sendo:\n",
    "\n",
    "$$A^TAx = A^Tb$$\n",
    "\n",
    "Essas equações também podem ser escritas da forma:\n",
    "\n",
    "$$x = (A^TA)^{-1}A^Tb$$\n",
    "\n",
    "<div class=\"alert\">\n",
    "3.2. SOLUÇÃO INGÊNUA\n",
    "</div>\n",
    "\n",
    "A solução ingênua (também chamada de solução direta) recebe esse nome por ser o método mais simples de resolução da regressão linear, mas que ao mesmo tempo não resolve todos os casos de maneira eficiente. Ela implementa exatamente a forma mais simples das equações normais, ou seja, $x = (A^TA)^{-1}A^Tb$, onde $x$ é o vetor resultado da regressão linear.\n",
    "\n",
    "<div class=\"alert\">\n",
    "3.3. CHOLESKY\n",
    "</div>\n",
    "\n",
    "O método de Cholesky utiliza o mesmo princípio de funcionamento do método da decomposição LU.\n",
    "\n",
    "<blockquote>\n",
    "<b>Para relembrar:</b>\n",
    "    \n",
    "A decomposição LU é um método que decompõe a matriz $A$, através de ordenações e permutações, em um produto $A = LU$, onde as matrizes $L$ e $U$ são triangulares inferiores e superiores, respectivamente.\n",
    "</blockquote>\n",
    "\n",
    "Cholesky, semelhantemente, fatora a matriz $A$ em outras duas matrizes, sendo uma triangular inferior e outra triangular superior. Porém, esta segunda é exatamente a matriz transversa da primeira, ou seja:\n",
    "\n",
    "$$A = LL^T$$\n",
    "\n",
    "Para a regressão linear, Cholesky trabalha para resolver as equações normais do tipo $A^TAx = A^Tb$ utilizando a matriz __pseudo-inversa__ de Moore-Penrose, também conhecida como __matriz inversa generalizada__.\n",
    "\n",
    "<blockquote>\n",
    "<b>Pseudo-inversa de Moore-Penrose:</b>\n",
    "    \n",
    "Quando desejamos encontrar um certo $x$ a partir de $Ax = y$, mas $A$ não é invertível, ou possui o seu determinante próximo de zero, então, se existir uma certa matriz $G$, onde $Gy = x$, então $G$ é chamada de matriz inversa generalizada de $A$. (SAMEJIMA, [20--]).\n",
    "</blockquote>\n",
    "\n",
    "Desta forma, utilizando as equações normais $A^TAx = A^Tb$, se $A$ for uma matriz de posto completo não invertível, então sua pseudo-inversa será $(A^TA)^{-1}A^T$. Cholesky utiliza isso para determinar uma certa matriz $R$, triangular superior, tal que $A^TA = R^TR$.\n",
    "\n",
    "Assim sendo, então:\n",
    "\n",
    "$$A^TAx = A^Tb$$\n",
    "$$R^TRx = A^Tb$$\n",
    "\n",
    "Seja $Rx = w$, em que $w$ é o vetor de coeficientes da matriz $R$:\n",
    "\n",
    "$$R^Tw = A^Tb$$\n",
    "\n",
    "Desta forma, a partir de $Rx = w$, encontramos em $x$ o resultado final para a regressão linear.\n",
    "\n",
    "<div class=\"alert\">\n",
    "3.4. FATORAÇÃO QR\n",
    "</div>\n",
    "\n",
    "A fatoração QR de uma matriz, também conhecida como decomposição QR, é um método que decompõe uma matriz $A_{m \\times n}$ em um produto $A = QR$, onde $Q_{m \\times m}$ é uma matriz ortogonal e $R_{m \\times n}$ uma matriz triangular superior. A fatoração QR é frequentemente usada para resolver o problema de mínimos quadrados linear e é a base para um determinado algoritmo de autovalores, o algoritmo QR.\n",
    "\n",
    "Se desejamos resolver $Ax = b$, a fatoração QR encontra as duas matrizes $Q$ e $R$, tal que $A = QR$.\n",
    "\n",
    "Seja sempre $Q$ uma matriz ortogonal. Se $A = QR$, então\n",
    "\n",
    "$$QRx = b$$\n",
    "\n",
    "Multiplicando ambos os lados por $Q^T$, temos:\n",
    "\n",
    "$$Q^TQRx = Q^Tb$$\n",
    "\n",
    "De acordo com as propriedades de matrizes, uma certa matriz $A$ é ortogonal se sua transposta for igual a sua inversa, ou seja, se $A^T$ = $A^{-1}$. Desta forma, como sabemos, pela definição da fatoração QR, que $Q$ é ortogonal, logo $Q^T$ = $Q^{-1}$. Modificando a fórmula acima, temos:\n",
    "\n",
    "$$Q^{-1}QRx = Q^{-1}b$$\n",
    "\n",
    "Ainda de acordo com as propriedades de matrizes, se uma certa matriz $A$ é quadrada e invertível, então:\n",
    "\n",
    "$$AA^{-1} = A^{-1}A = I \\text{(matriz identidade)}$$\n",
    "\n",
    "Já que toda matriz ortogonal é invertível, e como a matriz $Q$ é quadrada, então:\n",
    "\n",
    "$$QQ^{-1} = Q^{-1}Q = I$$\n",
    "\n",
    "Logo,\n",
    "\n",
    "$$Q^{-1}QRx = Q^{-1}b$$\n",
    "$$IRx = Q^{-1}b$$\n",
    "\n",
    "Neste ponto, novamente de acordo com as propriedades de matrizes, qualquer matriz $A$ multiplicada pela sua identidade $I$ é igual a própria matriz $A$. Desta forma, se $AI = IA = A$, então:\n",
    "\n",
    "$$IR = RI = R$$\n",
    "\n",
    "Logo,\n",
    "\n",
    "$$IRx = Q^{-1}b$$\n",
    "$$Rx = Q^{-1}b$$\n",
    "\n",
    "Como $Q$ é ortogonal, e sabendo que $Q^{-1}$ = $Q^T$, então:\n",
    "\n",
    "$$Rx = Q^Tb$$\n",
    "\n",
    "Desta forma, com $Rx = Q^Tb$, encontramos em $x$ o resultado final para a regressão linear.\n",
    "\n",
    "<div class=\"alert\">\n",
    "3.5. SVD\n",
    "</div>\n",
    "\n",
    "A sigla SVD vem do inglês _singular value decomposition_, que em tradução no português, significa __decomposição em valores singulares__. Esse método consiste na decomposição da matriz $A_{m \\times n}$ em um produto $A = U \\Sigma V$, onde as matrizes $U_{m \\times m}$ e $V^T_{n \\times n}$ são ortogonais, e a matriz $\\Sigma_{m \\times n}$ é diagonal.\n",
    "\n",
    "Para resolver a regressão linear usando esse método, usando as equações normais, temos que:\n",
    "\n",
    "$$Ax = b$$\n",
    "\n",
    "Sendo $A = U \\Sigma V$, então:\n",
    "\n",
    "$$Ax = b$$\n",
    "$$U \\Sigma V = b$$\n",
    "$$\\Sigma Vx = U^Tb$$\n",
    "\n",
    "Seja $Vx = w$, então:\n",
    "\n",
    "$$\\Sigma w = U^Tb$$\n",
    "\n",
    "Desta forma, com $\\Sigma w = U^Tb$, encontramos em $x$ o resultado final para a regressão linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "4. IMPLEMENTAÇÃO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez expostos os algoritmos para fatoração linear, podemos discorrer sobre a implementação dos mesmos, declarando as funções usando a linguagem de programação Python e seus pacotes, bibliotecas e métodos.\n",
    "\n",
    "<blockquote>\n",
    "<b>Observação:</b>\n",
    "\n",
    "Nesta seção, não executaremos as funções. Elas só serão declaradas e explicadas. A execução de cada código será realizada na próxima seção (5. CASOS DE USO).\n",
    "</blockquote>\n",
    "\n",
    "Primeiramente, precisamos importar:\n",
    "\n",
    "<ul>\n",
    "    <li>O pacote NumPy, que oferece suporte a arrays e matrizes multidimensionais, possuindo uma grande coleção de funções matemáticas que trabalha com estas estruturas; e</li>\n",
    "    <li>A biblioteca SciPy, que foi desenvolvida para trabalhar com arrays NumPy, e fornece muitas rotinas amigáveis e bem eficientes como rotinas para integração numérica e otimização.</li>\n",
    "</ul>\n",
    "\n",
    "Desses, usaremos alguns métodos que serão melhores descritos ao longo dessa seção.\n",
    "\n",
    "Essas importações estão sendo realizadas abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "4.1. SOLUÇÃO INGÊNUA\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que possamos calcular a regressão linear usando esse método, retornaremos à explicação das equações normais, que diz que:\n",
    "\n",
    "$$x = (A^TA)^{-1}A^Tb$$\n",
    "\n",
    "Esse é o método mais simples de implementar, necessitando apenas de:\n",
    "\n",
    "<ul>\n",
    "    <li>@: operador para multiplicação matricial;</li>\n",
    "    <li>T: atributo dos arrays NumPy para matriz transversa; e</li>\n",
    "    <li>inv(): método do pacote linalg, do NumPy, que recebe uma matriz $A$ do tipo ndarray (array n-dimensional) e devolve $A^{-1}$, ou seja, a matriz inversa da matriz passada como entrada.</li>\n",
    "</ul>\n",
    "\n",
    "A implementação desse algoritmo está declarada abaixo, com a função \"ls_naive()\", que recebe como entrada a matriz $A$ e o seu vetor de coeficientes $b$, e devolve o resultado da regressão linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_naive(A, b):\n",
    "    return np.linalg.inv(A.T @ A) @ A.T @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "4.2. CHOLESKY\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o método de Cholesky, que decompõe a matriz $A$ de tal forma que $A = LL^T$ para calcular a regressão linear, precisaremos de:\n",
    "\n",
    "<ul>\n",
    "    <li>@: operador para multiplicação matricial;</li>\n",
    "    <li>T: atributo dos arrays NumPy para matriz transversa;</li>\n",
    "    <li>cholesky(): método do pacote linalg, da biblioteca SciPy, que recebe uma matriz $A$ do tipo ndarray (array n-dimensional) e realiza a decomposição Cholesky dessa matriz, devolvendo $L$ ou $L^T$, ou seja, a matriz triangular inferior ou superior, respectivamente, dependendo do parâmetro lower passado (este, quando omitido, faz com que o método devolva $L^T$ por padrão); e</li>\n",
    "    <li>solve_triangular(): método do pacote linalg, da biblioteca SciPy, que recebe uma matriz $A$ e seu vetor de coeficientes $b$, e realiza o cálculo do sistema triangular superior ou inferior (dependendo da matriz passada como entrada), devolvendo o resultado final.</li>\n",
    "</ul>\n",
    "\n",
    "Para calcularmos a regressão linear usando esse método, faremos assim:\n",
    "\n",
    "1. Calcularemos a matriz triangular superior $L^T$, e a chamaremos de $R$;\n",
    "2. Calcularemos a resolução para o sistema triangular superior obtido no passo 1, no formato $Rx = w$, e a chamaremos de $w$; e\n",
    "3. Calcularemos a resolução para o sistema triangular obtido no passo 1, passando $w$ como vetor de coeficientes, obtendo o resultado final.\n",
    "\n",
    "Esse código está implementado na função \"ls_chol()\", declarada abaixo, que recebe como entrada a matriz $A$ e o seu vetor de coeficientes $b$, e devolve o resultado da regressão linear:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_chol(A, b):\n",
    "    #passo 1\n",
    "    R = sp.linalg.cholesky(A.T @ A)\n",
    "    \n",
    "    #passo 2\n",
    "    w = sp.linalg.solve_triangular(R, A.T @ b, trans='T')    \n",
    "    \n",
    "    #passo 3\n",
    "    return sp.linalg.solve_triangular(R, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<b>Observação:</b>\n",
    "\n",
    "O parâmetro trans='T' passado para o método solve_triangular(), indica para esse método que o sistema a ser calculado é do formato $A^Tx = b$.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "4.3. FATORAÇÃO QR\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o método da fatoração QR, que decompõe a matriz $A$ de tal forma que $A = QR$ para calcular a regressão linear, precisaremos de:\n",
    "\n",
    "<ul>\n",
    "    <li>@: operador para multiplicação matricial;</li>\n",
    "    <li>T: atributo dos arrays NumPy para matriz transversa;</li>\n",
    "    <li>qr(): método do pacote linalg, da biblioteca SciPy, que recebe uma matriz $A$ do tipo ndarray (array n-dimensional) e realiza a fatoração QR dessa matriz, devolvendo $Q$ e $R$; e</li>\n",
    "    <li>solve_triangular(): método do pacote linalg, da biblioteca SciPy, que recebe uma matriz $A$ e seu vetor de coeficientes $b$, e realiza o cálculo do sistema triangular superior ou inferior (dependendo da matriz passada como entrada), devolvendo o resultado final.</li>\n",
    "</ul>\n",
    "\n",
    "Para calcularmos a regressão linear usando esse método, faremos assim:\n",
    "\n",
    "1. Calcularemos a matriz $Q$ e a matriz $R$; e\n",
    "2. Calcularemos a resolução para o sistema triangular superior ($R$) obtido no passo 1, passando $Q^Tb$ como vetor de coeficientes, obtendo o resultado final.\n",
    "\n",
    "Esse código está implementado na função \"ls_qr()\", declarada abaixo, que recebe como entrada a matriz $A$ e o seu vetor de coeficientes $b$, e devolve o resultado da regressão linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_qr(A,b):\n",
    "    #passo 1\n",
    "    Q, R = sp.linalg.qr(A, mode='economic')\n",
    "    \n",
    "    #passo 2\n",
    "    return sp.linalg.solve_triangular(R, Q.T @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<b>Observação:</b>\n",
    "\n",
    "O parâmetro mode='economic' passado para o método qr(), indica para esse método que a fatoração a ser calculada é do tipo reduzido, ou seja, que considera as matriz $Q$ e $R$ como tendo as dimensões $m \\times k$ e $k \\times n$, respectivamente, em vez de $m \\times m$ e $m \\times n$, também respectivamente, onde $k = \\text{min}(m, n)$.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "4.4. SVD\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método de decomposição SVD decompõe a matriz $A$ de tal forma que $A = U \\Sigma V$ para calcular a regressão linear. Para esse método, precisaremos de:\n",
    "\n",
    "<ul>\n",
    "    <li>@: operador para multiplicação matricial;</li>\n",
    "    <li>T: atributo dos arrays NumPy para matriz transversa; e</li>\n",
    "    <li>svd(): método do pacote linalg, da biblioteca SciPy, que recebe uma matriz $A$ do tipo ndarray (array n-dimensional) e realiza a decomposição em valores singulares (SVD) dessa matriz, devolvendo $U$, $\\Sigma$ e $V$.</li>\n",
    "</ul>\n",
    "\n",
    "Para calcularmos a regressão linear usando esse método, faremos assim:\n",
    "\n",
    "1. Calcularemos as matrizes $U$, $\\Sigma$ e $V$, usando o método SVD;\n",
    "2. Calcularemos $w$, através de $\\Sigma w = U^Tb$; e\n",
    "3. Calcularemos o resultado final, através de $V^Tw.\n",
    "\n",
    "Esse código está implementado na função \"ls_svd()\", declarada abaixo, que recebe como entrada a matriz $A$ e o seu vetor de coeficientes $b$, e devolve o resultado da regressão linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_svd(A,b):\n",
    "    #passo 1\n",
    "    U, sigma, Vh = sp.linalg.svd(A, full_matrices=False, lapack_driver='gesdd')\n",
    "    \n",
    "    #passo 2\n",
    "    w = (U.T @ b)/ sigma\n",
    "    \n",
    "    #passo 3\n",
    "    return Vh.T @ w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<b>Observação 1:</b>\n",
    "\n",
    "O parâmetro full_matrices=False' passado para o método svd(), indica para esse método que as matrizes $U$ e $V$ a serem devolvidas terão as dimensões $m \\times k$ e $k \\times n$, respectivamente, onde $k = \\text{min}(m,n)$.\n",
    "\n",
    "<br><br>\n",
    "<b>Observação 2:</b>\n",
    "\n",
    "O parâmetro lapack_driver='gesdd' passado para o método svd(), indica para esse método que ele deve decompor a matriz em valores singulares utilizando a estratégia de dividir para conquistar, que, segundo a documentação da biblioteca, é mais eficiente do que a abordagem retangular geral ('gesvd').\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "5. CASOS DE USO\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez implementados os métodos, podemos utilizá-los com aplicações reais, utilizando conjuntos de dados existentes. Abaixo, está o resultado da execução dos métodos descritos acima para dois exemplos de problemas de regressão linear, com dois conjuntos de dados diferentes. São eles:\n",
    "\n",
    "1. Conjunto de dados de diabetes; e\n",
    "2. Conjunto de dados de habitação da Califórnia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para executar tanto o exemplo do notebook proposto para o projeto, quanto o exemplo do conjunto de dados de habitação da califórnia, se faz necessária a importação da biblioteca scikit-learn, com seus pacotes model_selection e preprocessing, dos quais utilizaremos os métodos train_test_split() e PolynomialFeatures, respectivamente. Essas importações estão declaradas abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "5.1. CONJUNTO DE DADOS DE DIABETES (PROPOSTO NO NOTEBOOK DO PROJETO)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, a definição do conjunto de dados de diabetes (load_diabetes()):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "\n",
    "data = datasets.load_diabetes()\n",
    "\n",
    "feature_names=['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
    "\n",
    "trn,test,y_trn,y_test = train_test_split(data.data, data.target, test_size=0.2)\n",
    "\n",
    "trn_int = np.c_[trn, np.ones(trn.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "5.1.1. Solução ingênua\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  28.659346, -235.991111,  473.401019,  368.855286, -686.474493,\n",
       "        333.43768 ,   47.354058,  167.464902,  723.764742,   43.705624,\n",
       "        152.284468])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_naive = ls_naive(trn_int, y_trn)\n",
    "coeffs_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "5.1.2. Cholesky\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  28.659346, -235.991111,  473.401019,  368.855286, -686.474493,\n",
       "        333.43768 ,   47.354058,  167.464902,  723.764742,   43.705624,\n",
       "        152.284468])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_chol = ls_chol(trn_int, y_trn)\n",
    "coeffs_chol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "5.1.3. Fatoração QR\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  28.659346, -235.991111,  473.401019,  368.855286, -686.474493,\n",
       "        333.43768 ,   47.354058,  167.464902,  723.764742,   43.705624,\n",
       "        152.284468])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_qr = ls_qr(trn_int, y_trn)\n",
    "coeffs_qr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "5.1.4. SVD\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  28.659346, -235.991111,  473.401019,  368.855286, -686.474493,\n",
       "        333.43768 ,   47.354058,  167.464902,  723.764742,   43.705624,\n",
       "        152.284468])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_svd = ls_svd(trn_int, y_trn)\n",
    "coeffs_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "5.2. CONJUNTO DE DADOS DE HABITAÇÃO DA CALIFÓRNIA\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, a definição do conjunto de dados de habitação da califórnia (fetch_california_housing()):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "\n",
    "data = datasets.fetch_california_housing()\n",
    "\n",
    "feature_names=['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitutde', 'Longitude']\n",
    "\n",
    "trn,test,y_trn,y_test = train_test_split(data.data, data.target, test_size=0.2)\n",
    "\n",
    "trn_int = np.c_[trn, np.ones(trn.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "5.2.1. Solução ingênua\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.357524e-01,  9.426138e-03, -1.057384e-01,  6.287204e-01,\n",
       "       -5.935071e-06, -3.873733e-03, -4.188930e-01, -4.306964e-01,\n",
       "       -3.655712e+01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_naive = ls_naive(trn_int, y_trn)\n",
    "coeffs_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "5.2.2. Cholesky\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.357524e-01,  9.426138e-03, -1.057384e-01,  6.287204e-01,\n",
       "       -5.935071e-06, -3.873733e-03, -4.188930e-01, -4.306964e-01,\n",
       "       -3.655712e+01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_chol = ls_chol(trn_int, y_trn)\n",
    "coeffs_chol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "5.2.3. Fatoração QR\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.357524e-01,  9.426138e-03, -1.057384e-01,  6.287204e-01,\n",
       "       -5.935071e-06, -3.873733e-03, -4.188930e-01, -4.306964e-01,\n",
       "       -3.655712e+01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_qr = ls_qr(trn_int, y_trn)\n",
    "coeffs_qr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "5.2.4. SVD\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.357524e-01,  9.426138e-03, -1.057384e-01,  6.287204e-01,\n",
       "       -5.935071e-06, -3.873733e-03, -4.188930e-01, -4.306964e-01,\n",
       "       -3.655712e+01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_svd = ls_svd(trn_int, y_trn)\n",
    "coeffs_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados finais obtidos ao final da execução de cada uma das funções, é o resultado da regressão linear para cada um dos conjuntos de dados, usando cada um dos métodos descritos nesse documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "6. REFERÊNCIAS\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BROWNLEE, Jason. __How to Solve Linear Regression Using Linear Algebra__. 2018. Disponível em: <<https://machinelearningmastery.com/solve-linear-regression-using-linear-algebra/>>. Acesso em: 02 maio 2021.\n",
    "\n",
    "GRAÇA, Ana Beatriz Rodrigues de Andrade. __Problemas de Mínimos Quadrados:__ Resolução e Apicações. 2016. 90 f. Trabalho de Conclusão de Curso (BACHARELADO)–Curso de Matemática, Instituto de Ciências Exatas, Universidade Federal Fluminense, Volta Redonda, 2016.\n",
    "\n",
    "NUMPY.ORG. __NumPy Documentation__. Disponível em: <<https://numpy.org/doc/stable/contents.html>>. Acesso em: 05 maio 2021.\n",
    "\n",
    "SAMEJIMA, Kim. __MATD41-Introdução aos modelos lineares:__ 2.1 – Inversas generalizadas. [20--]. Institudo de Matemática e Estatística, Universidade Federal da Bahia, [20--].\n",
    "\n",
    "SCIKIT-LEARN. __User Guide__. Disponível em: <<https://scikit-learn.org/stable/user_guide.html>>. Acesso em: 09 maio 2021.\n",
    "\n",
    "SCIPY.ORG. __Documentation__. Disponível em: <<https://www.scipy.org/docs.html>>. Acesso em: 05 maio 2021.\n",
    "\n",
    "THOMAS, Raquel. __5. Health Outcomes with Linear Regression__. (Jupyter Notebook). Disponível em: <<https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/5.%20Health%20Outcomes%20with%20Linear%20Regression.ipynb#End>>. Acesso em: 02 maio 2021.\n",
    "\n",
    "THOMAS, Raquel. __6. How to Implement Linear Regression__. (Jupyter Notebook). Disponível em: <<https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/6.%20How%20to%20Implement%20Linear%20Regression.ipynb#6.-How-to-Implement-Linear-Regression>>. Acesso em: 02 maio 2021."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
